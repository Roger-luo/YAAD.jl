<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · YAAD.jl</title><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-89508993-1', 'auto');
ga('send', 'pageview');
</script><link rel="canonical" href="https://rogerluo.me/YAAD.jl/latest/index.html"/><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>YAAD.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>Home</a><ul class="internal"><li><a class="toctext" href="#Batched-Operations-1">Batched Operations</a></li><li><a class="toctext" href="#Operator-Traits-1">Operator Traits</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Home</a></li></ul><a class="edit-page" href="https://github.com/Roger-luo/YAAD.jl/blob/master/docs/src/index.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Home</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Yet-Another-Automatic-Differentiation-1" href="#Yet-Another-Automatic-Differentiation-1">Yet Another Automatic Differentiation</a></h1><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.arg" href="#YAAD.arg"><code>YAAD.arg</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">arg(node, i) -&gt; ArgumentType</code></pre><p>Returns the <code>i</code>-th argument of the call in <code>node</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.args" href="#YAAD.args"><code>YAAD.args</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">args(node) -&gt; Tuple</code></pre><p>Returns the arguments of the call in <code>node</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.backward" href="#YAAD.backward"><code>YAAD.backward</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">backward(node) -&gt; nothing</code></pre><p>Backward evaluation of the comput-graph.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.forward" href="#YAAD.forward"><code>YAAD.forward</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">forward(node) -&gt; output</code></pre><p>Forward evaluation of the comput-graph. This method will call the operator in the comput-graph and update the cache.</p><pre><code class="language-none">forward(f, args...) -&gt; output</code></pre><p>For function calls.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.gradient" href="#YAAD.gradient"><code>YAAD.gradient</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">gradient(node, grad)</code></pre><p>Returns the gradient.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.operator" href="#YAAD.operator"><code>YAAD.operator</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">operator(node) -&gt; YAAD.Operator</code></pre><p>Returns the operator called in this node.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.register-Tuple{Any,Vararg{Any,N} where N}" href="#YAAD.register-Tuple{Any,Vararg{Any,N} where N}"><code>YAAD.register</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">register(f, args...; kwargs...)</code></pre><p>This is just a alias for constructing a <code>CachedNode</code>. But notice this function is used for register a node in <code>tape</code> in the global tape version implementation:</p><p>https://github.com/Roger-luo/YAAD.jl/tree/tape</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.value" href="#YAAD.value"><code>YAAD.value</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">value(node)</code></pre><p>Returns the value when forwarding at current node. <code>value</code> is different than <a href="#YAAD.forward"><code>forward</code></a> method, <code>value</code> only returns what the node contains, it will throw an error, if this node does not contain anything.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.AbstractNode" href="#YAAD.AbstractNode"><code>YAAD.AbstractNode</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">AbstractNode</code></pre><p>Abstract type for nodes in computation graph.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.CachedNode" href="#YAAD.CachedNode"><code>YAAD.CachedNode</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">CachedNode{NT, OutT} &lt;: AbstractNode</code></pre><p>Stores the cache of output with type <code>OutT</code> from a node of type <code>NT</code> in comput-graph. CachedNode is mutable, its output can be updated by <a href="#YAAD.forward"><code>forward</code></a>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.LeafNode" href="#YAAD.LeafNode"><code>YAAD.LeafNode</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">LeafNode &lt;: AbstractNode</code></pre><p>Abstract type for leaf nodes in a computation graph.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.Node" href="#YAAD.Node"><code>YAAD.Node</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Node{FT, ArgsT} &lt;: AbstractNode</code></pre><p>General node in a comput-graph. It stores a callable operator <code>f</code> of type <code>FT</code> and its arguments <code>args</code> in type <code>ArgsT</code> which should be a tuple.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.Variable" href="#YAAD.Variable"><code>YAAD.Variable</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Variable{T} &lt;: LeafNode</code></pre><p>A kind of leaf node. A general type for variables in a comput-graph. Similar to PyTorch&#39;s Variable, gradient will be accumulated to <code>var.grad</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.PrintTrait" href="#YAAD.PrintTrait"><code>YAAD.PrintTrait</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">PrintTrait(node) -&gt; Trait</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.backward_type_assert" href="#YAAD.backward_type_assert"><code>YAAD.backward_type_assert</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">backward_type_assert(node, grad)</code></pre><p>throw more readable error msg for backward type check.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.kwargs" href="#YAAD.kwargs"><code>YAAD.kwargs</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">kwargs(node) -&gt; NamedTuple</code></pre><p>Returns the keyword arguements of the call in <code>node</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.uncat-Tuple{Any,Any,Vararg{Any,N} where N}" href="#YAAD.uncat-Tuple{Any,Any,Vararg{Any,N} where N}"><code>YAAD.uncat</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-none">uncat(dims, cat_output, xs...) -&gt; Vector{SubArray}</code></pre><p>The reverse operation of [<code>Base.cat</code>], it will return corresponding [<code>Base.view</code>] of the inputs of a <code>cat</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.ComputGraphStyle" href="#YAAD.ComputGraphStyle"><code>YAAD.ComputGraphStyle</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">ComputGraphStyle &lt;: Broadcast.BroadcastStyle</code></pre><p>This style of broadcast will forward the broadcast expression to be registered in a computation graph, rather than directly calculate it.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.Operator" href="#YAAD.Operator"><code>YAAD.Operator</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Operator</code></pre><p>Abstract type for operators in the computation graph.</p></div></div></section><h2><a class="nav-anchor" id="Batched-Operations-1" href="#Batched-Operations-1">Batched Operations</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.Batched" href="#YAAD.Batched"><code>YAAD.Batched</code></a> — <span class="docstring-category">Module</span>.</div><div><div><p>Batched operation in Julia.</p><p>This module wraps some useful batched operation with a plain for-loop on CPU. All the functions in this module are defined with gradients in YAAD.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.Batched.ScalarIdentity" href="#YAAD.Batched.ScalarIdentity"><code>YAAD.Batched.ScalarIdentity</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">ScalarIdentity{B, K, T} &lt;: AbstractArray{T, 3}</code></pre><p>A batch of scalar multiplies a batch of identities, where batch size is <code>B</code>, each identity&#39;s size is <code>K</code>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.Batched.Transpose" href="#YAAD.Batched.Transpose"><code>YAAD.Batched.Transpose</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Transpose{B, T, AT &lt;: AbstractArray{T, 3}} &lt;: AbstractArray{T, 3}</code></pre><p>Batched transpose. Transpose a batch of matrix.</p></div></div></section><h2><a class="nav-anchor" id="Operator-Traits-1" href="#Operator-Traits-1">Operator Traits</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.Trait" href="#YAAD.Trait"><code>YAAD.Trait</code></a> — <span class="docstring-category">Module</span>.</div><div><div><pre><code class="language-none">Trait</code></pre><p>This module contains function traits as a subtype of <a href="#YAAD.Operator"><code>Operator</code></a>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.Trait.Broadcasted" href="#YAAD.Trait.Broadcasted"><code>YAAD.Trait.Broadcasted</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Broadcasted{FT} &lt;: Operator</code></pre><p>This trait wraps a callable object that being broadcasted. It will help to dispatch different gradient methods overloaded for broadcasted operation comparing to <a href="#YAAD.Trait.Method"><code>Method</code></a>.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="YAAD.Trait.Method" href="#YAAD.Trait.Method"><code>YAAD.Trait.Method</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-none">Method{FT} &lt;: Operator</code></pre><p>This trait wraps a callable object in Julia (usually a <code>Function</code>).</p></div></div></section><footer><hr/></footer></article></body></html>
